{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0b5471a7441e71a2e9077fc9f1edb69a69142e0d51daa994c89e6186fa4151e97",
   "display_name": "Python 3.8.10 64-bit ('d2l': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "So you've got 1 soul(s) in your hands, eh?\nWell, goodluck and Godspeed.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy = True\n",
    "#   Above is for the IntelliSense module to work.\n",
    "import tensorflow as tf\n",
    "gpus = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(f\"So you've got {gpus} soul(s) in your hands, eh?\\nWell, goodluck and Godspeed.\")\n",
    "\n",
    "#   To prevent a total meltdown of my GPU, restrictions needed to be made.\n",
    "rtx2080 = tf.config.experimental.list_physical_devices('GPU')\n",
    "for num in rtx2080:\n",
    "    tf.config.experimental.set_memory_growth(num, True)"
   ]
  },
  {
   "source": [
    "**Creating a sample tensor**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "x = tf.range(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(12,) tf.Tensor(12, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = x.shape\n",
    "b = tf.size(x)\n",
    "print(a,b)\n",
    "#   Note that the damn thing is kinda the same, just different ways of seeing it - I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is X tf.Tensor(\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]], shape=(3, 4), dtype=int32)\nAnd this is J tf.Tensor(\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.reshape(x, (3,4)); print('This is X', X)\n",
    "\n",
    "#   Now we reshape the thing so that it becomes a 3x4 matrix - still a tensor(-ish, with one two dimension so technically it is.)\n",
    "#   Good thing about ML and tensors are that they are quite smart, watch this shit.\n",
    "J = tf.reshape(x, (-1,4)); print('And this is J', J)\n",
    "\n",
    "#   Where the -1 states that \"Do it yourself, blockheaded bitch.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       " array([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       " array([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       " \n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]], dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#   In a real use case however, we wanna populate these tensors with useful datas,\n",
    "#   either zeroes or ones, or even random distributions.\n",
    "#   For zeros:\n",
    "zeroes = tf.zeros((2,3,4))\n",
    "#   My guesss is that create a Tensor with (2) dimensions, with each dimension of (3) by (4)\n",
    "#   I don't know, I'm new to this.\n",
    "#   For ones:\n",
    "ones = tf.ones((2,3,4))\n",
    "zeroes, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[-2.0948133 , -0.1436514 ,  0.659115  ,  1.3215209 ],\n",
       "        [-0.7327848 , -1.4577098 ,  0.03880419, -1.0673419 ],\n",
       "        [-0.28489622,  0.62033564,  0.685288  ,  0.45897585]],\n",
       "\n",
       "       [[ 1.1391335 ,  0.3063209 ,  0.7682058 , -1.6338375 ],\n",
       "        [-0.59788406, -0.24085988, -0.64743227, -2.0702207 ],\n",
       "        [ 0.6423083 ,  0.5162608 ,  0.04243708, -1.1106051 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#   As stated before, we wanted a data in there, so for this purposes - lets do a Normal (Gaussian) Distribution random function:\n",
    "tf.random.normal(shape=[2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 4., 8.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([2., 2., 2., 2.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 3.,  4.,  6., 10.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1.,  0.,  2.,  6.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 2.,  4.,  8., 16.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5, 1. , 2. , 4. ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 1.,  4., 16., 64.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
       " array([2.7182817e+00, 7.3890562e+00, 5.4598148e+01, 2.9809580e+03],\n",
       "       dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#   Now lets do some Operations, note that due to the nature of this - all of the operators are now performing\n",
    "#   As an ELEMENTWISE operations. ก็คือ \"ทำแม่งทั้งก้อน\" -SY (2021).\n",
    "x = tf.constant([1.0, 2, 4, 8])\n",
    "y = tf.constant([2.0, 2, 2, 2])\n",
    "x, y, x+y, x-y, x*y, x/y, x**y, tf.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(6, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [ 2.,  1.,  4.,  3.],\n",
       "        [ 1.,  2.,  3.,  4.],\n",
       "        [ 4.,  3.,  2.,  1.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]], dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#   Remember that \"np.append\" bullshit, now he has grown into 'concatenate'-tion:\n",
    "X = tf.reshape(tf.range(12, dtype=tf.float32), (3,4))\n",
    "Y = tf.constant([[2.0,1,4,3], [1,2,3,4], [4,3,2,1]], dtype=tf.float32)\n",
    "#   What is intriguing is that the first tensor element of a constant tensor, must be \n",
    "#   a goddamn float, else the damn thing just collapses.\n",
    "#   Ok I know now, this is due to the fact that the X tensor is a float type, and if \n",
    "#   we don't specify the Y tensor as a float, it would kill itself.\n",
    "tf.concat([X,Y], axis = 0), tf.concat([X,Y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=bool, numpy=\n",
       "array([[False,  True, False,  True],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#   This can also be operated through boolean\n",
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=66.0>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#   And to 'shrink' it all into 1x1:\n",
    "tf.reduce_sum(X)"
   ]
  },
  {
   "source": [
    "## Automatic Differentiation\n",
    "Suppose we want to find a derivative of:\n",
    "y = 2x^T x; where dy/dx  \n",
    "*which in our world is: y = 2x^2*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "x = tf.range(4, dtype = tf.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=28.0>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.,  4.,  8., 12.], dtype=float32)>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#   Before we go any further, we have to now ACTUALLY store it. Wow.\n",
    "x = tf.Variable(x)\n",
    "#   Then we can calculate:\n",
    "with tf.GradientTape() as t:\n",
    "    y = 2*tf.tensordot(x, x, axes=1)\n",
    "\n",
    "#   Which we can now find the gradient of the scalars output\n",
    "x_grad = t.gradient(y,x)\n",
    "y, x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#   Now we should get [0 4 8 12]; which means that at x = 0, it is 0 and so on.\n",
    "#   Hence, intuitively - we can say that the derivative of this function is 4x.\n",
    "#   Lets proove that its true.\n",
    "x_grad == 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 2., 4., 6.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#   This can also be done in a way such as:\n",
    "#   y = x^2 = x * x\n",
    "with tf.GradientTape() as t:\n",
    "    y = x * x\n",
    "t.gradient(y,x)\n",
    "#   Which is, you guessed it - 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}